{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "BOARD_ROWS,BOARD_COLS = 3,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "currentdir = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that defines the state of the board, also gives players rewards at the end of games\n",
    "class State:\n",
    "    \n",
    "    # p1 and p2 are the agents that are playing\n",
    "    def __init__(self, p1, p2):\n",
    "        # Board is always 3x3 for tic tac toe\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.gameOver = False\n",
    "        # init player1 always starts, 1 for p1, -1 for p2\n",
    "        self.playerTurn = 1\n",
    "        \n",
    "    # Get a unique hash value that corresponds with the current board state\n",
    "    # This is used to store the board state in a state-value dictionary\n",
    "    def getHash(self):\n",
    "        return str(self.board.reshape(BOARD_ROWS * BOARD_COLS))\n",
    "    \n",
    "    def reset(self):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.gameOver = False\n",
    "        self.playerTurn = 1\n",
    "    \n",
    "    # Update vacant positions after a turn is made\n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i,j] == 0:\n",
    "                    # Coordinates need to be in tuple form\n",
    "                    positions.append((i,j))\n",
    "        return positions\n",
    "    \n",
    "    # For when a player makes a move\n",
    "    def updateBoard(self, position):\n",
    "        self.board[position] = self.playerTurn\n",
    "        # Switch to other player\n",
    "        self.playerTurn = -1 if self.playerTurn == 1 else 1\n",
    "        \n",
    "    # After each move, check if there's a winner and give out rewards\n",
    "    def winner(self):\n",
    "        # Row win\n",
    "        for i in range(BOARD_ROWS):\n",
    "            # p1 wins\n",
    "            if sum(self.board[i, :]) == 3:\n",
    "                self.gameOver = True\n",
    "                return 1\n",
    "            # p2 wins\n",
    "            elif sum(self.board[i, :]) == -3:\n",
    "                self.gameOver = True\n",
    "                return -1\n",
    "            \n",
    "        # Column win \n",
    "        for i in range(BOARD_COLS):\n",
    "            if sum(self.board[:, i]) == 3:\n",
    "                self.gameOver = True\n",
    "                return 1\n",
    "            elif sum(self.board[:, i]) == -3:\n",
    "                self.gameOver = True\n",
    "                return -1\n",
    "            \n",
    "        # Diagonal win\n",
    "        diag1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
    "        diag2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)])\n",
    "        if diag1 == 3 or diag2 == 3:\n",
    "            self.gameOver = True\n",
    "            return 1\n",
    "        elif diag1 == -3 or diag2 == -3:\n",
    "            self.gameOver = True\n",
    "            return -1\n",
    "        \n",
    "        # Tie\n",
    "        if not len(self.availablePositions()):\n",
    "            self.gameOver = True\n",
    "            return 0\n",
    "        \n",
    "        # Game not over\n",
    "        self.gameOver = False\n",
    "        return None\n",
    "    \n",
    "    # Give rewards only if game is over\n",
    "    def giveReward(self):\n",
    "        result = self.winner()\n",
    "        if result > 0:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result < 0:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        # Tying is worse than winning but better than losing\n",
    "        # Also since p1 has an advantage going first, they get less of a reward for ties\n",
    "        else:\n",
    "            self.p1.feedReward(.1)\n",
    "            self.p2.feedReward(.5)\n",
    "            \n",
    "    # Simulate a single player's turn\n",
    "    # If human is True, print extra output to show extra results\n",
    "    def playTurn(self, player, human=False):\n",
    "        openPositions = self.availablePositions()\n",
    "        playerAction = player.chooseAction(openPositions, self.board, self.playerTurn)\n",
    "        # Update board state with action\n",
    "        self.updateBoard(playerAction)\n",
    "        boardHash = self.getHash()\n",
    "        player.addState(boardHash)\n",
    "        # Check board for winner\n",
    "        result = self.winner()\n",
    "        # When there's a human player, print out stuff\n",
    "        if human:\n",
    "            self.showBoard()\n",
    "            if result is not None:\n",
    "                if result == 1:\n",
    "                    print(f\"{self.p1.name} wins!\")\n",
    "                elif result == -1:\n",
    "                    print(f\"{self.p2.name} wins!\")\n",
    "                else:\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        elif result is not None:\n",
    "            self.giveReward()\n",
    "            self.p1.reset()\n",
    "            self.p2.reset()\n",
    "            self.reset()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    # Simulate playing games with 2 agents\n",
    "    def play(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            while not self.gameOver:\n",
    "                # Player1\n",
    "                if self.playTurn(self.p1):\n",
    "                    break \n",
    "                # Player2\n",
    "                if self.playTurn(self.p2):\n",
    "                    break\n",
    "    \n",
    "    # Play human vs agent\n",
    "    def playInteractive(self):\n",
    "        while not self.gameOver:\n",
    "            # Player1\n",
    "            print(f\"{p1.name} going...\")\n",
    "            if self.playTurn(self.p1, True):\n",
    "                break \n",
    "            # Player2\n",
    "            print(f\"{p2.name} going...\")\n",
    "            if self.playTurn(self.p2, True):\n",
    "                break\n",
    "                    \n",
    "    def showBoard(self):\n",
    "        # p1: x  p2: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super class for players (both human and agent)\n",
    "class Player:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def chooseAction(self, positions, currentBoard=None, turn=None):\n",
    "        pass\n",
    "        \n",
    "    def addState(self, state):\n",
    "        pass\n",
    "    \n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "    \n",
    "    def reset():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that defines agent players\n",
    "# Two of these players will be learning and playing with each other\n",
    "class AgentPlayer:\n",
    "    def __init__(self, name, explRate=.3):\n",
    "        self.name = name\n",
    "        # Implement epsilon-greedy method of selecting actions\n",
    "        # Default .3 value means 30% of time agent takes random action, 70% of time agent takes greedy action\n",
    "        self.explRate = explRate\n",
    "        # Record all positions taken\n",
    "        self.states = []\n",
    "        # Learning rate \n",
    "        self.lr = .2\n",
    "        self.decayGamma = .9\n",
    "        # State -> Value\n",
    "        self.statesValue = {}\n",
    "        \n",
    "    # Get a unique hash value that corresponds with the given board state\n",
    "    def getHash(self, board):\n",
    "        return str(board.reshape(BOARD_ROWS * BOARD_COLS))\n",
    "    \n",
    "    # Using this abstraction because HumanPlayer class will have this as well\n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "        \n",
    "    def chooseAction(self, openPositions, currentBoard, turn):\n",
    "        if np.random.uniform(0,1) <= self.explRate:\n",
    "            # Take random action\n",
    "            index = np.random.choice(len(openPositions))\n",
    "            action = openPositions[index]\n",
    "        else:\n",
    "            maxValue = -999\n",
    "            for p in openPositions:\n",
    "                nextBoard = currentBoard.copy()\n",
    "                nextBoard[p] = turn\n",
    "                nextBoardHash = self.getHash(nextBoard)\n",
    "                value = 0 if self.statesValue.get(nextBoardHash) is None else self.statesValue.get(nextBoardHash)\n",
    "                if value > maxValue:\n",
    "                    maxValue = value\n",
    "                    action = p\n",
    "        return action\n",
    "    \n",
    "    # At the end of the game, backpropogate and update state values\n",
    "    # The updated value of state t equals the current value of state t\n",
    "    #   adding the difference between the value of next state and the value of current state,\n",
    "    #   which is multiplied by a learning rate Î± (Given the reward of intermediate state is 0)\n",
    "    def feedReward(self, reward):\n",
    "        for state in (reversed(self.states)):\n",
    "            if self.statesValue.get(state) is None:\n",
    "                self.statesValue[state] = 0\n",
    "            self.statesValue[state] += self.lr * (self.decayGamma * reward - self.statesValue[state])\n",
    "            reward = self.statesValue[state]\n",
    "    \n",
    "    # For when there's a new round\n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "\n",
    "    # After training, an agent has its policy stored in self.stateValues\n",
    "    # This can be saved to play against a human player\n",
    "    def savePolicy(self):\n",
    "        fw = open(currentdir + '/policies/oldpolicy_' + str(self.name), 'wb')\n",
    "        pickle.dump(self.statesValue, fw)\n",
    "        fw.close()\n",
    "\n",
    "    # Loading the policy when playing a human\n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file, 'rb')\n",
    "        self.statesValue = pickle.load(fr)\n",
    "        fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for human player\n",
    "# Mostly inherited from super class Player\n",
    "class HumanPlayer(Player):    \n",
    "    def chooseAction(self, positions, currentBoard=None, turn=None):\n",
    "        while True:\n",
    "            try:\n",
    "                i = int(input(\"Input action row-> \"))\n",
    "                j = int(input(\"Input action column-> \"))\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if (i, j) in positions:\n",
    "                return (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "saved p1 policy\n",
      "saved p2 policy\n"
     ]
    }
   ],
   "source": [
    "# Train agents\n",
    "p1 = AgentPlayer(\"p1\")\n",
    "p2 = AgentPlayer(\"p2\")\n",
    "state = State(p1, p2)\n",
    "print(\"training...\")\n",
    "state.play(1000)\n",
    "# Save Results\n",
    "p1.savePolicy()\n",
    "print(\"saved p1 policy\")\n",
    "p2.savePolicy()\n",
    "print(\"saved p2 policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer going...\n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "human going...\n",
      "Input action row-> 1\n",
      "Input action column-> 1\n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "computer going...\n",
      "-------------\n",
      "| x | x |   | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "human going...\n",
      "Input action row-> 0\n",
      "Input action column-> 2\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "computer going...\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "| x | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "human going...\n",
      "Input action row-> 2\n",
      "Input action column-> 0\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "| x | o |   | \n",
      "-------------\n",
      "| o |   |   | \n",
      "-------------\n",
      "human wins!\n"
     ]
    }
   ],
   "source": [
    "# Human play with trained p1\n",
    "# Make sure Agent isn't training anymore\n",
    "p1 = AgentPlayer(\"computer\", explRate=0)\n",
    "p1.loadPolicy(\"policy_p1\")\n",
    "p2 = HumanPlayer(\"human\")\n",
    "state = State(p1, p2)\n",
    "state.playInteractive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human going...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2c4f2fea7ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"policy_p2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayInteractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-a45e4331d5ab>\u001b[0m in \u001b[0;36mplayInteractive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Player1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p1.name} going...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayTurn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Player2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a45e4331d5ab>\u001b[0m in \u001b[0;36mplayTurn\u001b[0;34m(self, player, human)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplayTurn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mopenPositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailablePositions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mplayerAction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchooseAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenPositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayerTurn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;31m# Update board state with action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayerAction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-32d204cacccb>\u001b[0m in \u001b[0;36mchooseAction\u001b[0;34m(self, positions, currentBoard, turn)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input action row-> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input action column-> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Human play with trained p2\n",
    "# Make sure Agent isn't training anymore\n",
    "p1 = HumanPlayer(\"human\")\n",
    "p2 = AgentPlayer(\"computer\", explRate=0)\n",
    "p2.loadPolicy(\"policy_p2\")\n",
    "state = State(p1, p2)\n",
    "state.playInteractive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
